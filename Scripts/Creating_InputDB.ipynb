{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Creating the input database for ecPoint-Calibrate\n\n### What does this Jupyter notebook?\nThis Jupyter notebook will generate the input database, for forecasts and observations, in the format required by ecPoint-Calibrate.\n\n### What raw forecasts will be used?\nThe raw forecasts that will be used in this Jupyter notebook come from form the Integrated Forecasting System (IFS) of the European Centre for Medium-range Weather Forecasts (ECMWF). The forecasts come from an experiment run to create forecasts with the the 47r1 version of the IFS, for a period between January 1st and December 31st, 2019. The forecasts are provided in grib format.\n\n### What raw observations will be used used?\nThe raw observations used in this software are the \"Global Surface Summary of Day\" product produced by the NOAA's National Centers for Environmental Information (NCEI). The observations are freely downloadable from https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/ and are processed with pandas and Metview (https://pypi.org/project/metview/). From all the parameters in the raw files, this Jupyter notebook will use only:\n1. Precipitation amount for 24 hours, PRCP (.01 inches)\n2. Mean temperature over 24 hours, TEMP (.1 Fahrenheit)\nThe observations will be converted in geopoints, and the units will get converted in mm for precipitation, and Celsius degrees for temperature.\n\nNOTE: each file contains all the observations for the year at a specific station\n_______________________________________________________________________________________________________________________________"},{"metadata":{},"cell_type":"markdown","source":"## Setting the environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport fileinput\nfrom datetime import date, datetime, timedelta\nimport numpy as np\nimport pandas as pd\nimport metview as mv","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# INPUT PARAMETERS\nDateS = date(2019, 1, 2)\nDateF = date(2019, 1, 2)\nDelta_Date = timedelta(days=1)\nWorkDir = os.path.dirname(os.getcwd())\nRawData_Dir = \"RawData\"\nInputDB_Dir = \"InputDB\" \nFC_Dir = \"FC\"\nOBS_Dir = \"OBS\"","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CREATING SOME ENVIRONMENT VARIABLES\nRawData_FC_Dir = WorkDir + \"/\" + RawData_Dir + \"/\" + FC_Dir\nRawData_OBS_Dir = WorkDir + \"/\" + RawData_Dir + \"/\" + OBS_Dir\nInputDB_prcp_Dir = WorkDir + \"/\" + InputDB_Dir + \"/Rainfall\"\nInputDB_temp_Dir = WorkDir + \"/\" + InputDB_Dir + \"/Temperature\"\nInputDB_prcp_FC_Dir = InputDB_prcp_Dir + \"/\" + FC_Dir\nInputDB_prcp_OBS_Dir = InputDB_prcp_Dir + \"/\" + OBS_Dir\nInputDB_temp_FC_Dir = InputDB_temp_Dir + \"/\" + FC_Dir\nInputDB_temp_OBS_Dir = InputDB_temp_Dir + \"/\" + OBS_Dir","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create the InputDB for observations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# List all the raw observation files in the directory \"RawData_OBS_Dir\"\narr = os.listdir(RawData_OBS_Dir)\nprint(\"NOTE:\")\nprint(\"There are \" + str(len(arr)) + \" stations around the globe to analyse.\")\n\n# Begining of the observations pre-processing\n# NOTE: each day of the year will be pre-process at a time\nTheDate = DateS\nwhile TheDate <= DateF:\n    \n    TheDateSTR = TheDate.strftime(\"%Y-%m-%d\")\n    print(\" \")\n    print(\"Pre-Processing observations for \" + TheDateSTR)\n    now = datetime.now()\n    print(\"Starting at... \", now.strftime(\"%H:%M:%S\"))\n    \n    # Generating empty dataframes for each day of the year\n    df_prcp = pd.DataFrame()\n    df_temp = pd.DataFrame()\n    \n    for RawData_OBS_Filename in arr:\n        \n        # Read the raw observations for each station\n        RawData_OBS_File = RawData_OBS_Dir + \"/\" + RawData_OBS_Filename\n        df = pd.read_csv(RawData_OBS_File)\n        df1 = df[df[\"DATE\"].isin([TheDateSTR])] #selection of the date of interest\n        \n        # Pre-processing of precipitation observations\n        df1_prcp = df1[[\"STATION\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"PRCP\", \"PRCP_ATTRIBUTES\"]]\n        frames = [df_prcp, df1_prcp]\n        df_prcp = pd.concat(frames)\n          \n        # Pre-processing of temperature observations\n        df1_temp = df1[[\"STATION\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TEMP\", \"TEMP_ATTRIBUTES\"]]\n        frames = [df_temp, df1_temp]\n        df_temp = pd.concat(frames)\n\n        \n    # ------------------------------------------ #\n    # Pre-processing of precipitation observations\n    df_prcp = df_prcp[df_prcp.PRCP != 99.99] # eliminating the missing values\n    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"A\"] # eliminating the stations that reported only 1 report of 6-hour precipitation amount.\n    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"B\"] # eliminating the stations that reported only the summation of 2 reports of 6-hour precipitation amount.\n    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"C\"] # eliminating the stations that reported only the summation of 3 reports of 6-hour precipitation amount.\n    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"E\"] # eliminating the stations that reported only 1 report of 12-hour precipitation amount.\n    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"H\"] # eliminating the stations that reported incomplete data for the day.\n    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"I\"] # eliminating the stations that did not report any precipitation data for the day.\n    df_prcp[\"PRCP\"] = df_prcp[\"PRCP\"] * 25.4 # converting rainfall in mm from inches.\n    del df_prcp['PRCP_ATTRIBUTES'] # eliminate the \"PRCS_ATTRIBUTES\" column from the final output\n    df_prcp.rename(columns={\"STATION\":\"stnid\",\"LATITUDE\":\"latitude\",\"LONGITUDE\":\"longitude\",\"ELEVATION\":\"level\",\"DATE\":\"date\",\"PRCP\":\"value_0\"}, inplace=True) # changing the name of the dataframe columns\n    df_prcp.insert (5, \"time\", 0) # adding \"time\" column\n    df_prcp[\"date\"] = pd.to_datetime(df_prcp[\"date\"]).dt.strftime('%Y%m%d') # change date format\n    print(\"Total n. of rainfall observations maintained: \" + str(len(df_prcp)))\n    \n    # Pre-processing of temperature observations\n    df_temp = df_temp[df_temp.TEMP != 9999.9] # eliminating the missing values.\n    df_temp = df_temp[df_temp.TEMP_ATTRIBUTES >= 20] # eliminating those reports that did not provide hourly observations for at least 20 hours in the day.\n    df_temp[\"TEMP\"] = (df_temp[\"TEMP\"] - 32) * (5/9) # converting temperature in Celsius from Farenheit degrees.\n    del df_temp['TEMP_ATTRIBUTES'] # eliminate the \"TEMP_ATTRIBUTES\" column from the final output\n    df_temp.rename(columns={\"STATION\":\"stnid\",\"LATITUDE\":\"latitude\",\"LONGITUDE\":\"longitude\",\"ELEVATION\":\"level\",\"DATE\":\"date\",\"PRCP\":\"value_0\"}, inplace=True) # changing the name of the dataframe columns\n    df_temp.insert (5, \"time\", 0) # adding \"time\" column\n    df_temp[\"date\"] = pd.to_datetime(df_temp[\"date\"]).dt.strftime('%Y%m%d') # change date format\n    print(\"Total n. of temperature observations maintained: \" + str(len(df_temp)))\n    \n    \n    # ------------------------------------- #\n    # Creating the geopoint files\n    TheDate_File = TheDate + timedelta(days=1)\n    TheDateSTR_File = TheDate_File.strftime(\"%Y%m%d\")\n    \n    #################\n    # Precipitation #\n    #################\n    \n    # Create the directory if it doesn't exist\n    InputDB_prcp_OBS_Dir_temp = InputDB_prcp_OBS_Dir + \"/\" + TheDateSTR_File\n    if not os.path.exists(InputDB_prcp_OBS_Dir_temp): \n        os.makedirs(InputDB_prcp_OBS_Dir_temp)\n    \n    # Extract the headers for the geopoint file\n    InputDB_prcp_OBS_csvFile = InputDB_prcp_OBS_Dir_temp + \"/\" + TheDateSTR_File + \"00.csv\"\n    df_prcp.to_csv(InputDB_prcp_OBS_csvFile, index=False, sep='\\t')\n    inFile = open(InputDB_prcp_OBS_csvFile)\n    buffer = []\n    for line in inFile:\n        buffer.append(line)\n    Headers = buffer[0]\n    \n    # Save csv file (without headers)\n    df_prcp.to_csv(InputDB_prcp_OBS_csvFile, index=False, sep='\\t', header=None)\n\n    # Composing the geopoint file\n    Header_File = InputDB_prcp_OBS_Dir_temp + \"/\" + \"Header.txt\"\n    outF = open(Header_File, \"w\")\n    outF.write(\"#GEO\\n#FORMAT NCOLS\\n#COLUMNS\\n# Missing values represented by 3e+38 (not user-changeable)\\n\")\n    outF.write(Headers)\n    outF.write(\"#METADATA\\n\")\n    outF.write(\"date=\" + TheDateSTR_File)\n    outF.write(\"\\nlevel=0\\nparam=tp\\nparameter=tp\\nperiod=43200\\nstep=0\\ntime=0000\\nunits=mm\\n#DATA\\n\")\n    outF.close()\n\n    Files2Merge = [Header_File,InputDB_prcp_OBS_csvFile]\n    InputDB_prcp_OBS_geoFile = InputDB_prcp_OBS_Dir_temp + \"/\" + TheDateSTR_File + \"00.geo\"\n    with open(InputDB_prcp_OBS_geoFile, 'w') as fout, fileinput.input(Files2Merge) as fin:\n        for line in fin:\n            fout.write(line)\n    \n    # Remove temporary files\n    os.remove(Header_File)\n    os.remove(InputDB_prcp_OBS_csvFile)\n    \n    \n    ###############\n    # Temperature #\n    ###############\n    \n    \n    TheDate += Delta_Date\n\n    now = datetime.now()\n    print(\"Ending at... \", now.strftime(\"%H:%M:%S\"))","execution_count":7,"outputs":[{"output_type":"stream","text":"NOTE:\nThere are 12352 stations around the globe to analyse.\n \nPre-Processing observations for 2019-01-02\nStarting at...  08:59:19\nTotal n. of rainfall observations maintained: 5762\nTotal n. of temperature observations maintained: 6928\nEnding at...  09:02:07\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot rainfall observations\nInputDB_prcp_OBS_File = \"/home/jovyan/InputDB/Rainfall/OBS/20190102/2019010200.geo\"\nprint(InputDB_prcp_OBS_File)\ng = mv.read(InputDB_prcp_OBS_File)\n\n# To display plots within the Jupyter notebook\nmv.setoutput(\"jupyter\")\n\nmy_coast = mv.mcoast(\n    map_coastline_land_shade        = \"on\",\n    map_coastline_land_shade_colour = \"RGB(0.89,0.89,0.89)\",\n    map_coastline_sea_shade         = \"on\",\n    map_coastline_sea_shade_colour  = \"grey\",\n    map_grid_latitude_increment     = 20,\n    map_grid_longitude_increment    = 40,\n    map_grid_colour                 = \"charcoal\"\n    )\n\nmy_symbol = mv.msymb(\n    legend                               = \"on\",\n    symbol_type                          = \"marker\",\n    symbol_marker_index                  = 15,\n    symbol_table_mode                    = \"advanced\",\n    symbol_outline                       = \"on\",\n    symbol_advanced_table_selection_type = \"list\",\n    symbol_advanced_table_level_list     = [0,0.001,1,2,5,10,30,50,100,200],\n    symbol_advanced_table_colour_method  = \"list\",\n    symbol_advanced_table_colour_list    = [\"rgb(204, 230, 255)\",\"rgb(0, 136, 204)\",\"rgb(0, 255, 191)\",\"rgb(204, 255, 153)\",\"rgb(255, 255, 102)\",\"rgb(255, 204, 153)\",\"rgb(255, 102, 0)\",\"rgb(204, 0, 102)\",\"rgb(102, 0, 102)\"],\n    symbol_advanced_table_height_list    = 0.5\n)\n\n# Plot\nmv.plot(my_coast,my_symbol,g)","execution_count":12,"outputs":[{"output_type":"stream","text":"/home/jovyan/InputDB/Rainfall/OBS/20190102/2019010200.geo\n","name":"stdout"},{"output_type":"error","ename":"Exception","evalue":"Metview error: Error calling Metview function","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-3c8837946621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_coast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_symbol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/metview/bindings.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0moutput_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0mmet_setoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0mmet_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/metview/bindings.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_result_as_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue_from_metview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/metview/bindings.py\u001b[0m in \u001b[0;36mvalue_from_metview\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_return_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Metview error: Error calling Metview function"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.remove(header)\nInputDB_prcp_OBS_File = InputDB_prcp_OBS_Dir_temp + \"/\" + TheDateSTR_File + \"00.csv\"\nos.remove(InputDB_prcp_OBS_File)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the input database for ecPoint-Calibrate\n",
    "\n",
    "### What does this Jupyter notebook?\n",
    "This Jupyter notebook will generate the input database, for forecasts and observations, in the format required by ecPoint-Calibrate.\n",
    "\n",
    "### What raw forecasts will be used?\n",
    "The raw forecasts that will be used in this Jupyter notebook come from form the Integrated Forecasting System (IFS) of the European Centre for Medium-range Weather Forecasts (ECMWF). The forecasts come from an experiment run to create forecasts with the the 47r1 version of the IFS, for a period between January 1st and December 31st, 2019. The forecasts are provided in grib format.\n",
    "\n",
    "### What raw observations will be used used?\n",
    "The raw observations used in this software are the \"Global Surface Summary of Day\" product produced by the NOAA's National Centers for Environmental Information (NCEI). The observations are freely downloadable from https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/ and are processed with pandas and Metview (https://pypi.org/project/metview/). From all the parameters in the raw files, this Jupyter notebook will use only:\n",
    "1. Precipitation amount for 24 hours, PRCP (.01 inches)\n",
    "2. Mean temperature over 24 hours, TEMP (.1 Fahrenheit)\n",
    "The observations will be converted in geopoints, and the units will get converted in mm for precipitation, and Celsius degrees for temperature.\n",
    "\n",
    "NOTE: each file contains all the observations for the year at a specific station\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date, datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT PARAMETERS\n",
    "DateS = date(2019, 1, 1)\n",
    "DateF = date(2019, 1, 1)\n",
    "Delta_Date = timedelta(days=1)\n",
    "WorkDir = \"C:/Users/f_ati/OneDrive/Desktop/GitHub/ecPointCalibrate_CaseStudy\"\n",
    "RawData_Dir = \"RawData\"\n",
    "InputDB_Dir = \"InputDB\" \n",
    "FC_Dir = \"FC\"\n",
    "OBS_Dir = \"OBS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING SOME ENVIRONMENT VARIABLES\n",
    "RawData_FC_Dir = WorkDir + \"/\" + RawData_Dir + \"/\" + FC_Dir\n",
    "RawData_OBS_Dir = WorkDir + \"/\" + RawData_Dir + \"/\" + OBS_Dir\n",
    "InputDB_FC_Dir = WorkDir + \"/\" + InputDB_Dir + \"/\" + FC_Dir\n",
    "InputDB_OBS_Dir = WorkDir + \"/\" + InputDB_Dir + \"/\" + OBS_Dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the InputDB for observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the raw observation files in the directory \"RawData_OBS_Dir\"\n",
    "arr = os.listdir(RawData_OBS_Dir)\n",
    "print(\"NOTE:\")\n",
    "print(\"There are \" + str(len(arr)) + \" stations around the globe to analyse.\")\n",
    "\n",
    "# Begining of the observations pre-processing\n",
    "# NOTE: each day of the year will be pre-process at a time\n",
    "TheDate = DateS\n",
    "while TheDate <= DateF:\n",
    "    \n",
    "    TheDateSTR = TheDate.strftime(\"%Y-%m-%d\")\n",
    "    print(\" \")\n",
    "    print(\"Pre-Processing observations for \" + TheDateSTR)\n",
    "    now = datetime.now()\n",
    "    print(\"Starting at... \", now.strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    # Generating empty dataframes for each day of the year\n",
    "    df_prcp = pd.DataFrame()\n",
    "    df_temp = pd.DataFrame()\n",
    "    \n",
    "    for RawData_OBS_Filename in arr:\n",
    "        \n",
    "        # Read the raw observations for each station\n",
    "        RawData_OBS_File = RawData_OBS_Dir + \"/\" + RawData_OBS_Filename\n",
    "        df = pd.read_csv(RawData_OBS_File)\n",
    "        df1 = df[df[\"DATE\"].isin([TheDateSTR])] #selection of the date of interest\n",
    "        \n",
    "        # Pre-processing of precipitation observations\n",
    "        df1_prcp = df1[[\"STATION\", \"DATE\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"PRCP\", \"PRCP_ATTRIBUTES\"]]\n",
    "        frames = [df_prcp, df1_prcp]\n",
    "        df_prcp = pd.concat(frames)\n",
    "        \n",
    "        # Pre-processing of temperature observations\n",
    "        df1_temp = df1[[\"STATION\", \"DATE\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"TEMP\", \"TEMP_ATTRIBUTES\"]]\n",
    "        frames = [df_temp, df1_temp]\n",
    "        df_temp = pd.concat(frames)\n",
    "\n",
    "    # Pre-processing of precipitation observations\n",
    "    df_prcp[\"LONGITUDE\"] = df_prcp[\"LONGITUDE\"] + 180 # to have longitudes from 0째 to 360째 \n",
    "    df_prcp = df_prcp[df_prcp.PRCP != 99.99] # eliminating the missing values\n",
    "    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"A\"] # eliminating the stations that reported only 1 report of 6-hour precipitation amount.\n",
    "    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"B\"] # eliminating the stations that reported only the summation of 2 reports of 6-hour precipitation amount.\n",
    "    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"C\"] # eliminating the stations that reported only the summation of 3 reports of 6-hour precipitation amount.\n",
    "    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"E\"] # eliminating the stations that reported only 1 report of 12-hour precipitation amount.\n",
    "    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"H\"] # eliminating the stations that reported incomplete data for the day.\n",
    "    df_prcp = df_prcp[df_prcp.PRCP_ATTRIBUTES != \"I\"] # eliminating the stations that did not report any precipitation data for the day.\n",
    "    df_prcp[\"PRCP\"] = df_prcp[\"PRCP\"] * 25.4 # converting rainfall in mm from inches.\n",
    "    del df_prcp['PRCP_ATTRIBUTES'] # eliminate the \"PRCS_ATTRIBUTES\" column from the final output\n",
    "    print(\"Total n. of rainfall observations maintained: \" + str(len(df_prcp)))\n",
    "    \n",
    "    # Pre-processing of temperature observations\n",
    "    df_temp[\"LONGITUDE\"] = df_temp[\"LONGITUDE\"] + 180 # to have longitudes from 0째 to 360째.\n",
    "    df_temp = df_temp[df_temp.TEMP != 9999.9] # eliminating the missing values.\n",
    "    df_temp = df_temp[df_temp.TEMP_ATTRIBUTES >= 20] # eliminating those reports that did not provide hourly observations for at least 20 hours in the day.\n",
    "    df_temp[\"TEMP\"] = (df_temp[\"TEMP\"] - 32) * (5/9) # converting temperature in Celsius from Farenheit degrees.\n",
    "    del df_temp['TEMP_ATTRIBUTES'] # eliminate the \"TEMP_ATTRIBUTES\" column from the final output\n",
    "    print(\"Total n. of temperature observations maintained: \" + str(len(df_temp)))\n",
    "    \n",
    "    TheDate += Delta_Date\n",
    "\n",
    "    now = datetime.now()\n",
    "    print(\"Ending at... \", now.strftime(\"%H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

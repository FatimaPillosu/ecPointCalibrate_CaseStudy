{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Input Database (InputDB) for ecPoint-Calibrate\n",
    "\n",
    "### What does this Jupyter notebook?\n",
    "This Jupyter notebook will generate the input database, for forecasts and observations, in the format required by ecPoint-Calibrate.\n",
    "\n",
    "### What raw forecasts will be used?\n",
    "The raw forecasts that will be used in this Jupyter notebook come from form the Integrated Forecasting System (IFS) of the European Centre for Medium-range Weather Forecasts (ECMWF). The forecasts come from an experiment run to create forecasts with the the 47r1 version of the IFS, for a period between January 1st and December 31st, 2019. The forecasts are provided in grib format.\n",
    "\n",
    "### What raw observations will be used used?\n",
    "The raw observations used in this software are the \"Global Surface Summary of Day\" product produced by the NOAA's National Centers for Environmental Information (NCEI). The observations are freely downloadable from https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/ and are processed with pandas and Metview (https://pypi.org/project/metview/). From all the parameters in the raw files, this Jupyter notebook will use only:\n",
    "1. Precipitation amount for 24 hours, PRCP (.01 inches)\n",
    "2. Mean temperature over 24 hours, TEMP (.1 Fahrenheit)\n",
    "The observations will be converted in geopoints, and the units will get converted in mm for precipitation, and Celsius degrees for temperature.\n",
    "\n",
    "NOTE: each file contains all the observations for the year at a specific station\n",
    "_______________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fileinput\n",
    "import tarfile\n",
    "from datetime import date, datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import metview as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT PARAMETERS\n",
    "DateS = date(2019, 1, 2)\n",
    "DateF = date(2019, 1, 2)\n",
    "Delta_Date = timedelta(days=1)\n",
    "WorkDir = os.path.dirname(os.getcwd())\n",
    "RawData_Dir = \"RawData\"\n",
    "InputDB_Dir = \"InputDB\" \n",
    "FC_Dir = \"FC\"\n",
    "OBS_Dir = \"OBS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING SOME ENVIRONMENT VARIABLES\n",
    "\n",
    "# Raw data and input database directories\n",
    "RawData_Dir = WorkDir + \"/\" + RawData_Dir\n",
    "InputDB_Dir = WorkDir + \"/\" + InputDB_Dir\n",
    "\n",
    "# Tared raw forecasts (FC) and observations (OBS) files\n",
    "FC_zip = RawData_Dir + \"/\" + FC_Dir + \".tar.gz\"\n",
    "OBS_zip = RawData_Dir + \"/\" + OBS_Dir + \".tar.gz\"\n",
    "\n",
    "# Untared raw FC and OBS files\n",
    "RawData_FC_Dir = RawData_Dir + \"/\" + FC_Dir\n",
    "RawData_OBS_Dir = RawData_Dir + \"/\" + OBS_Dir\n",
    "\n",
    "# Input database for ecPoint-Calibrate\n",
    "InputDB_prcp_FC_Dir = InputDB_Dir + \"/Rainfall/\" + FC_Dir\n",
    "InputDB_prcp_OBS_Dir = InputDB_Dir + \"/Rainfall/\" + OBS_Dir\n",
    "InputDB_temp_FC_Dir = InputDB_Dir + \"/Temperature/\" + FC_Dir\n",
    "InputDB_temp_OBS_Dir = InputDB_Dir + \"/Temperature/\" + OBS_Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the contents of /perm/mo/mofp/ecPointCalibrate_CaseStudy/RawData/OBS.tar.gz ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-81cc4b5e9a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting the contents of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mOBS_zip\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOBS_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawData_Dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python3/3.6.10-01/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[1;32m   2008\u001b[0m             \u001b[0;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[0;32m-> 2010\u001b[0;31m                          numeric_owner=numeric_owner)\n\u001b[0m\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m         \u001b[0;31m# Reverse sort directories.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python3/3.6.10-01/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2050\u001b[0m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[1;32m   2051\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m                                  numeric_owner=numeric_owner)\n\u001b[0m\u001b[1;32m   2053\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrorlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python3/3.6.10-01/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[1;32m   2120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2123\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/apps/python3/3.6.10-01/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[0;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Untar raw OBS\n",
    "print(\"Extracting the contents of \" + OBS_zip + \" ...\")\n",
    "tar = tarfile.open(OBS_zip)\n",
    "tar.extractall(path=RawData_Dir)\n",
    "tar.close()\n",
    "\n",
    "# Untar raw FC\n",
    "print(\"Extracting the contents of \" + FC_zip + \" ...\")\n",
    "tar = tarfile.open(FC_zip)\n",
    "tar.extractall(path=RawData_Dir)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the InputDB for OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE:\n",
      "There are 12352 stations around the globe to analyse.\n",
      " \n",
      "Pre-Processing observations for 2019-01-02\n",
      "Starting at...  08:59:19\n",
      "Total n. of rainfall observations maintained: 5762\n",
      "Total n. of temperature observations maintained: 6928\n",
      "Ending at...  09:02:07\n"
     ]
    }
   ],
   "source": [
    "# List all the raw observation files in the directory \"RawData_OBS_Dir\"\n",
    "arr = os.listdir(RawData_OBS_Dir)\n",
    "print(\"NOTE:\")\n",
    "print(\"There are \" + str(len(arr)) + \" stations around the globe to analyse.\")\n",
    "\n",
    "# Creation of the InputDB for OBS\n",
    "TheDate = DateS\n",
    "while TheDate <= DateF:\n",
    "    \n",
    "    TheDateSTR = TheDate.strftime(\"%Y-%m-%d\")\n",
    "    print(\" \")\n",
    "    print(\"Creating OBS's InputDB for day \" + TheDateSTR)\n",
    "    \n",
    "    \n",
    "    ##################################################\n",
    "    # MERGING GLOBAL OBSERVATIONS FOR CONSIDERED DAY #\n",
    "    ##################################################\n",
    "    \n",
    "    # Generating empty dataframes for the considered day\n",
    "    prcp = pd.DataFrame()\n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    for RawData_OBS_Filename in arr:\n",
    "        \n",
    "        # Read the raw observations for each station\n",
    "        RawData_OBS_File = RawData_OBS_Dir + \"/\" + RawData_OBS_Filename\n",
    "        df = pd.read_csv(RawData_OBS_File)\n",
    "        df1 = df[df[\"DATE\"].isin([TheDateSTR])] #selection of the date of interest\n",
    "        \n",
    "        # Selecting the variables of interest for precipitation\n",
    "        prcp1 = df1[[\"STATION\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"PRCP\", \"PRCP_ATTRIBUTES\"]]\n",
    "        frames = [prcp, prcp1]\n",
    "        prcp = pd.concat(frames)\n",
    "          \n",
    "        # Selecting the variables of interest for temperature\n",
    "        temp1 = df1[[\"STATION\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TEMP\", \"TEMP_ATTRIBUTES\"]]\n",
    "        frames = [temp, temp1]\n",
    "        temp = pd.concat(frames)\n",
    "\n",
    "        \n",
    "        \n",
    "    ###################################\n",
    "    # PRE-PROCESSING THE OBSERVATIONS #\n",
    "    ###################################\n",
    "    \n",
    "    # Precipitation observations\n",
    "    prcp = prcp[prcp.PRCP != 99.99] # eliminating the missing values\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"A\"] # eliminating the stations that reported only 1 report of 6-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"B\"] # eliminating the stations that reported only the summation of 2 reports of 6-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"C\"] # eliminating the stations that reported only the summation of 3 reports of 6-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"E\"] # eliminating the stations that reported only 1 report of 12-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"H\"] # eliminating the stations that reported incomplete data for the day.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"I\"] # eliminating the stations that did not report any precipitation data for the day.\n",
    "    prcp[\"PRCP\"] = prcp[\"PRCP\"] * 25.4 # converting rainfall in mm from inches.\n",
    "    del df_prcp['PRCP_ATTRIBUTES'] # eliminate the \"PRCS_ATTRIBUTES\" column from the final output\n",
    "    print(\"Total n. of rainfall observations maintained: \" + str(len(df_prcp)))\n",
    "    \n",
    "    # Temperature observations\n",
    "    df_temp = df_temp[df_temp.TEMP != 9999.9] # eliminating the missing values.\n",
    "    df_temp = df_temp[df_temp.TEMP_ATTRIBUTES >= 20] # eliminating those reports that did not provide hourly observations for at least 20 hours in the day.\n",
    "    df_temp[\"TEMP\"] = (df_temp[\"TEMP\"] - 32) * (5/9) # converting temperature in Celsius from Farenheit degrees.\n",
    "    del df_temp['TEMP_ATTRIBUTES'] # eliminate the \"TEMP_ATTRIBUTES\" column from the final output\n",
    "    print(\"Total n. of temperature observations maintained: \" + str(len(df_temp)))\n",
    "    \n",
    "    \n",
    "    ###########################\n",
    "    # CREATING GEOPOINT FILES #\n",
    "    ###########################\n",
    "    \n",
    "    # The files are named \n",
    "    TheDate_File = TheDate + timedelta(days=1)\n",
    "    TheDateSTR_File = TheDate_File.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    #################\n",
    "    # Precipitation #\n",
    "    #################\n",
    "    \n",
    "    # Create the directory if it doesn't exist\n",
    "    InputDB_prcp_OBS_Dir_temp = InputDB_prcp_OBS_Dir + \"/\" + TheDateSTR_File\n",
    "    if not os.path.exists(InputDB_prcp_OBS_Dir_temp): \n",
    "        os.makedirs(InputDB_prcp_OBS_Dir_temp)\n",
    "    \n",
    "    # Extract the headers for the geopoint file\n",
    "    InputDB_prcp_OBS_csvFile = InputDB_prcp_OBS_Dir_temp + \"/\" + TheDateSTR_File + \"00.csv\"\n",
    "    df_prcp.to_csv(InputDB_prcp_OBS_csvFile, index=False, sep='\\t')\n",
    "    inFile = open(InputDB_prcp_OBS_csvFile)\n",
    "    buffer = []\n",
    "    for line in inFile:\n",
    "        buffer.append(line)\n",
    "    Headers = buffer[0]\n",
    "    \n",
    "    # Save csv file (without headers)\n",
    "    df_prcp.to_csv(InputDB_prcp_OBS_csvFile, index=False, sep='\\t', header=None)\n",
    "\n",
    "    # Composing the geopoint file\n",
    "    Header_File = InputDB_prcp_OBS_Dir_temp + \"/\" + \"Header.txt\"\n",
    "    outF = open(Header_File, \"w\")\n",
    "    outF.write(\"#GEO\\n#FORMAT NCOLS\\n#COLUMNS\\n# Missing values represented by 3e+38 (not user-changeable)\\n\")\n",
    "    outF.write(Headers)\n",
    "    outF.write(\"#METADATA\\n\")\n",
    "    outF.write(\"date=\" + TheDateSTR_File)\n",
    "    outF.write(\"\\nlevel=0\\nparam=tp\\nparameter=tp\\nperiod=43200\\nstep=0\\ntime=0000\\nunits=mm\\n#DATA\\n\")\n",
    "    outF.close()\n",
    "\n",
    "    Files2Merge = [Header_File,InputDB_prcp_OBS_csvFile]\n",
    "    InputDB_prcp_OBS_geoFile = InputDB_prcp_OBS_Dir_temp + \"/\" + TheDateSTR_File + \"00.geo\"\n",
    "    with open(InputDB_prcp_OBS_geoFile, 'w') as fout, fileinput.input(Files2Merge) as fin:\n",
    "        for line in fin:\n",
    "            fout.write(line)\n",
    "    \n",
    "    # Remove temporary files\n",
    "    os.remove(Header_File)\n",
    "    os.remove(InputDB_prcp_OBS_csvFile)\n",
    "    \n",
    "    \n",
    "    ###############\n",
    "    # Temperature #\n",
    "    ###############\n",
    "    \n",
    "    \n",
    "    TheDate += Delta_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/InputDB/Rainfall/OBS/20190102/2019010200.geo\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Metview error: Error calling Metview function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3c8837946621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_coast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmy_symbol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/metview/bindings.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0moutput_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjupyter_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m             \u001b[0mmet_setoutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpng_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m             \u001b[0mmet_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/metview/bindings.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_result_as_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue_from_metview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.7/site-packages/metview/bindings.py\u001b[0m in \u001b[0;36mvalue_from_metview\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_return_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Metview error: Error calling Metview function"
     ]
    }
   ],
   "source": [
    "# Plot rainfall observations\n",
    "InputDB_prcp_OBS_File = \"/home/jovyan/InputDB/Rainfall/OBS/20190102/2019010200.geo\"\n",
    "print(InputDB_prcp_OBS_File)\n",
    "g = mv.read(InputDB_prcp_OBS_File)\n",
    "\n",
    "# To display plots within the Jupyter notebook\n",
    "mv.setoutput(\"jupyter\")\n",
    "\n",
    "my_coast = mv.mcoast(\n",
    "    map_coastline_land_shade        = \"on\",\n",
    "    map_coastline_land_shade_colour = \"RGB(0.89,0.89,0.89)\",\n",
    "    map_coastline_sea_shade         = \"on\",\n",
    "    map_coastline_sea_shade_colour  = \"grey\",\n",
    "    map_grid_latitude_increment     = 20,\n",
    "    map_grid_longitude_increment    = 40,\n",
    "    map_grid_colour                 = \"charcoal\"\n",
    "    )\n",
    "\n",
    "my_symbol = mv.msymb(\n",
    "    legend                               = \"on\",\n",
    "    symbol_type                          = \"marker\",\n",
    "    symbol_marker_index                  = 15,\n",
    "    symbol_table_mode                    = \"advanced\",\n",
    "    symbol_outline                       = \"on\",\n",
    "    symbol_advanced_table_selection_type = \"list\",\n",
    "    symbol_advanced_table_level_list     = [0,0.001,1,2,5,10,30,50,100,200],\n",
    "    symbol_advanced_table_colour_method  = \"list\",\n",
    "    symbol_advanced_table_colour_list    = [\"rgb(204, 230, 255)\",\"rgb(0, 136, 204)\",\"rgb(0, 255, 191)\",\"rgb(204, 255, 153)\",\"rgb(255, 255, 102)\",\"rgb(255, 204, 153)\",\"rgb(255, 102, 0)\",\"rgb(204, 0, 102)\",\"rgb(102, 0, 102)\"],\n",
    "    symbol_advanced_table_height_list    = 0.5\n",
    ")\n",
    "\n",
    "# Plot\n",
    "mv.plot(my_coast,my_symbol,g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(header)\n",
    "InputDB_prcp_OBS_File = InputDB_prcp_OBS_Dir_temp + \"/\" + TheDateSTR_File + \"00.csv\"\n",
    "os.remove(InputDB_prcp_OBS_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

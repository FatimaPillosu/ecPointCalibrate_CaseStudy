{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Input Database (InputDB) for ecPoint-Calibrate\n",
    "\n",
    "### What does this Jupyter notebook?\n",
    "This Jupyter notebook will generate the input database, for forecasts and observations, in the format required by ecPoint-Calibrate.\n",
    "\n",
    "### What raw forecasts will be used?\n",
    "The raw forecasts that will be used in this Jupyter notebook come from form the Integrated Forecasting System (IFS) of the European Centre for Medium-range Weather Forecasts (ECMWF). The forecasts come from an experiment run to create forecasts with the the 47r1 version of the IFS, for a period between January 1st and December 31st, 2019. The forecasts are provided in grib format.\n",
    "\n",
    "### What raw observations will be used used?\n",
    "The raw observations used in this software are the \"Global Surface Summary of Day\" product produced by the NOAA's National Centers for Environmental Information (NCEI). The observations are freely downloadable from https://www.ncei.noaa.gov/data/global-summary-of-the-day/archive/ and are processed with pandas and Metview (https://pypi.org/project/metview/). From all the parameters in the raw files, this Jupyter notebook will use only:\n",
    "1. Precipitation amount for 24 hours, PRCP (.01 inches)\n",
    "2. Mean temperature over 24 hours, TEMP (.1 Fahrenheit)\n",
    "The observations will be converted in geopoints, and the units will get converted in mm for precipitation, and Celsius degrees for temperature.\n",
    "\n",
    "NOTE: each file contains all the observations for the year at a specific station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________\n",
    "## Set the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import fileinput\n",
    "import tarfile\n",
    "from datetime import date, datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import metview as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT PARAMETERS\n",
    "DateS = date(2019, 1, 1)\n",
    "DateF = date(2019, 1, 1)\n",
    "Delta_Date = timedelta(days=1)\n",
    "WorkDir = os.path.dirname(os.getcwd())\n",
    "RawData_Dir = \"RawData\"\n",
    "InputDB_Dir = \"InputDB\" \n",
    "FC_Dir = \"FC\"\n",
    "OBS_Dir = \"OBS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING SOME ENVIRONMENT VARIABLES\n",
    "\n",
    "# Raw data and input database directories\n",
    "RawData_Dir = WorkDir + \"/\" + RawData_Dir\n",
    "InputDB_Dir = WorkDir + \"/\" + InputDB_Dir\n",
    "\n",
    "# Tared raw forecasts (FC) and observations (OBS) files\n",
    "FC_zip = RawData_Dir + \"/\" + FC_Dir + \".tar.gz\"\n",
    "OBS_zip = RawData_Dir + \"/\" + OBS_Dir + \".tar.gz\"\n",
    "\n",
    "# Untared raw FC and OBS files\n",
    "RawData_FC_Dir = RawData_Dir + \"/\" + FC_Dir\n",
    "RawData_OBS_Dir = RawData_Dir + \"/\" + OBS_Dir\n",
    "\n",
    "# Input database for ecPoint-Calibrate\n",
    "InputDB_prcp_FC_Dir = InputDB_Dir + \"/Rainfall/\" + FC_Dir\n",
    "InputDB_prcp_OBS_Dir = InputDB_Dir + \"/Rainfall/\" + OBS_Dir\n",
    "InputDB_temp_FC_Dir = InputDB_Dir + \"/Temperature/\" + FC_Dir\n",
    "InputDB_temp_OBS_Dir = InputDB_Dir + \"/Temperature/\" + OBS_Dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________________________________\n",
    "## Get the raw forecasts and observations (from Zenodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw FC and OBS have already been downloaded from Zenodo.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# DOWNLOAD THE RAW DATA FROM ZENODO \n",
    "# Note: it can take up to 1 hour\n",
    "\n",
    "RawData_ZenodoDOI=\"10.5281/zenodo.4642836\" \n",
    "cd ./../RawData\n",
    "if [[ -f \"FC.tar.gz\" && -f \"OBS.tar.gz\"   ]]; then\n",
    "    echo \"Raw FC and OBS have already been downloaded from Zenodo.\"\n",
    "else\n",
    "    echo \"Downloading raw FC and OBS from Zenodo...\"\n",
    "    zenodo_get ${RawData_ZenodoDOI}\n",
    "fi\n",
    "rm -rf md5sums.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw OBS has already been untared.\n",
      "Raw FC has already been untared.\n"
     ]
    }
   ],
   "source": [
    "# UNTAR RAW DATA\n",
    "\n",
    "# Observations\n",
    "# Note: it can take up to 5 minutes\n",
    "if path.exists(RawData_Dir + \"/OBS\") == True:\n",
    "    print(\"Raw OBS has already been untared.\")\n",
    "else:\n",
    "    print(\"Extracting the contents of \" + OBS_zip + \" ...\")\n",
    "    tar = tarfile.open(OBS_zip)\n",
    "    tar.extractall(path=RawData_Dir)\n",
    "    tar.close()\n",
    "\n",
    "# Forecasts\n",
    "# Note: it can take up to 30 minutes\n",
    "if path.exists(RawData_Dir + \"/FC\") == True:\n",
    "    print(\"Raw FC has already been untared.\")\n",
    "else:\n",
    "    print(\"Extracting the contents of \" + FC_zip + \" ...\")\n",
    "    tar = tarfile.open(FC_zip)\n",
    "    tar.extractall(path=RawData_Dir)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________\n",
    "## Create the input database for ecPoint-Calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE INPUT DATABASE FOR OBS\n",
    "# Note: it can take up to 3 hours\n",
    "\n",
    "# List all the raw observation files in the directory \"RawData_OBS_Dir\"\n",
    "arr = os.listdir(RawData_OBS_Dir)\n",
    "print(\"NOTE:\")\n",
    "print(\"There are \" + str(len(arr)) + \" stations around the globe to analyse.\")\n",
    "\n",
    "# Creation of the InputDB for OBS\n",
    "TheDate = DateS\n",
    "while TheDate <= DateF:\n",
    "    \n",
    "    TheDateSTR = TheDate.strftime(\"%Y-%m-%d\")\n",
    "    print(\" \")\n",
    "    print(\"Creating OBS's InputDB for day \" + TheDateSTR)\n",
    "    \n",
    "    \n",
    "    ##################################################\n",
    "    # MERGING GLOBAL OBSERVATIONS FOR CONSIDERED DAY #\n",
    "    ##################################################\n",
    "    \n",
    "    # Generating empty dataframes for the considered day\n",
    "    prcp = pd.DataFrame()\n",
    "    temp = pd.DataFrame()\n",
    "    \n",
    "    for RawData_OBS_Filename in arr:\n",
    "        \n",
    "        # Read the raw observations for each station\n",
    "        RawData_OBS_File = RawData_OBS_Dir + \"/\" + RawData_OBS_Filename\n",
    "        df = pd.read_csv(RawData_OBS_File)\n",
    "        df1 = df[df[\"DATE\"].isin([TheDateSTR])] #selection of the date of interest\n",
    "        \n",
    "        # Selecting the variables of interest for precipitation\n",
    "        prcp1 = df1[[\"STATION\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"PRCP\", \"PRCP_ATTRIBUTES\"]]\n",
    "        frames = [prcp, prcp1]\n",
    "        prcp = pd.concat(frames)\n",
    "          \n",
    "        # Selecting the variables of interest for temperature\n",
    "        temp1 = df1[[\"STATION\", \"LATITUDE\", \"LONGITUDE\", \"ELEVATION\", \"DATE\", \"TEMP\", \"TEMP_ATTRIBUTES\"]]\n",
    "        frames = [temp, temp1]\n",
    "        temp = pd.concat(frames)\n",
    "\n",
    "        \n",
    "    ###################################\n",
    "    # PRE-PROCESSING THE OBSERVATIONS #\n",
    "    ###################################\n",
    "    \n",
    "    # Precipitation observations\n",
    "    prcp = prcp[prcp.PRCP != 99.99] # eliminating the missing values\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"A\"] # eliminating the stations that reported only 1 report of 6-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"B\"] # eliminating the stations that reported only the summation of 2 reports of 6-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"C\"] # eliminating the stations that reported only the summation of 3 reports of 6-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"E\"] # eliminating the stations that reported only 1 report of 12-hour precipitation amount.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"H\"] # eliminating the stations that reported incomplete data for the day.\n",
    "    prcp = prcp[prcp.PRCP_ATTRIBUTES != \"I\"] # eliminating the stations that did not report any precipitation data for the day.\n",
    "    prcp[\"PRCP\"] = prcp[\"PRCP\"] * 25.4 # converting rainfall in mm from inches.\n",
    "    del prcp['PRCP_ATTRIBUTES'] # eliminate the \"PRCS_ATTRIBUTES\" column from the final output\n",
    "    print(\"Total n. of rainfall observations maintained: \" + str(len(prcp)))\n",
    "    \n",
    "    # Temperature observations\n",
    "    temp = temp[temp.TEMP != 9999.9] # eliminating the missing values.\n",
    "    temp = temp[temp.TEMP_ATTRIBUTES >= 20] # eliminating those reports that did not provide hourly observations for at least 20 hours in the day.\n",
    "    temp[\"TEMP\"] = (temp[\"TEMP\"] - 32) * (5/9) # converting temperature in Celsius from Farenheit degrees.\n",
    "    del temp['TEMP_ATTRIBUTES'] # eliminate the \"TEMP_ATTRIBUTES\" column from the final output\n",
    "    print(\"Total n. of temperature observations maintained: \" + str(len(temp)))\n",
    "    \n",
    "    \n",
    "    ###########################\n",
    "    # CREATING GEOPOINT FILES #\n",
    "    ###########################\n",
    "    \n",
    "    # The files are named with the date and time of the end of the period the observations refer to\n",
    "    TheDate_File = TheDate + timedelta(days=1)\n",
    "    TheDateSTR_File = TheDate_File.strftime(\"%Y%m%d\")\n",
    "    \n",
    "    # -------------------------- #\n",
    "    # Precipitation observations #\n",
    "    # -------------------------- #\n",
    "    \n",
    "    # Create the InputDB directory for the considered date if it doesn't exist\n",
    "    InputDB_prcp_OBS_Dir_temp = InputDB_prcp_OBS_Dir + \"/Acc24h/\" + TheDateSTR_File\n",
    "    if not os.path.exists(InputDB_prcp_OBS_Dir_temp): \n",
    "        os.makedirs(InputDB_prcp_OBS_Dir_temp)\n",
    "    \n",
    "    # Create the geopoint file (with Metview)\n",
    "    prcp_geo = mv.create_geo(type = \"standard\",\n",
    "                             latitudes = prcp[\"LATITUDE\"].to_numpy() ,\n",
    "                             longitudes = prcp[\"LONGITUDE\"].to_numpy(),\n",
    "                             levels = prcp[\"ELEVATION\"].to_numpy(),\n",
    "                             values = prcp[\"PRCP\"].to_numpy(),\n",
    "                             dates = int(TheDateSTR_File),\n",
    "                             times = 0)                    \n",
    "                    \n",
    "    # Saving the geopoint file\n",
    "    InputDB_prcp_OBS_File = InputDB_prcp_OBS_Dir_temp + \"/tp_24_\" + TheDateSTR_File + \"_00.geo\"\n",
    "    mv.write(InputDB_prcp_OBS_File, prcp_geo)\n",
    "    \n",
    "    \n",
    "    # ------------------------ #\n",
    "    # Temperature observations #\n",
    "    # ------------------------ #\n",
    "    \n",
    "    # Create the InputDB directory for the considered date if it doesn't exist\n",
    "    InputDB_temp_OBS_Dir_temp = InputDB_temp_OBS_Dir + \"/\" + TheDateSTR_File\n",
    "    if not os.path.exists(InputDB_temp_OBS_Dir_temp): \n",
    "        os.makedirs(InputDB_temp_OBS_Dir_temp)\n",
    "    \n",
    "    # Create the geopoint file (with Metview)\n",
    "    temp_geo = mv.create_geo(type = \"standard\",\n",
    "                            latitudes = temp[\"LATITUDE\"].to_numpy() ,\n",
    "                            longitudes = temp[\"LONGITUDE\"].to_numpy(),\n",
    "                            levels = temp[\"ELEVATION\"].to_numpy(),\n",
    "                            values = temp[\"TEMP\"].to_numpy(),\n",
    "                            dates = int(TheDateSTR_File),\n",
    "                            times = 0)                    \n",
    "                    \n",
    "    # Saving the geopoint file\n",
    "    InputDB_temp_OBS_File = InputDB_temp_OBS_Dir_temp + \"/t_\" + TheDateSTR_File + \"_00.geo\"\n",
    "    mv.write(InputDB_temp_OBS_File, temp_geo)\n",
    "    \n",
    "    \n",
    "    TheDate += Delta_Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________\n",
    "## Plot forecasts and observations (with Metview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rainfall observations\n",
    "InputDB_prcp_OBS_File = \"/home/jovyan/InputDB/Rainfall/OBS/20190102/2019010200.geo\"\n",
    "print(InputDB_prcp_OBS_File)\n",
    "g = mv.read(InputDB_prcp_OBS_File)\n",
    "\n",
    "# To display plots within the Jupyter notebook\n",
    "mv.setoutput(\"jupyter\")\n",
    "\n",
    "my_coast = mv.mcoast(\n",
    "    map_coastline_land_shade        = \"on\",\n",
    "    map_coastline_land_shade_colour = \"RGB(0.89,0.89,0.89)\",\n",
    "    map_coastline_sea_shade         = \"on\",\n",
    "    map_coastline_sea_shade_colour  = \"grey\",\n",
    "    map_grid_latitude_increment     = 20,\n",
    "    map_grid_longitude_increment    = 40,\n",
    "    map_grid_colour                 = \"charcoal\"\n",
    "    )\n",
    "\n",
    "my_symbol = mv.msymb(\n",
    "    legend                               = \"on\",\n",
    "    symbol_type                          = \"marker\",\n",
    "    symbol_marker_index                  = 15,\n",
    "    symbol_table_mode                    = \"advanced\",\n",
    "    symbol_outline                       = \"on\",\n",
    "    symbol_advanced_table_selection_type = \"list\",\n",
    "    symbol_advanced_table_level_list     = [0,0.001,1,2,5,10,30,50,100,200],\n",
    "    symbol_advanced_table_colour_method  = \"list\",\n",
    "    symbol_advanced_table_colour_list    = [\"rgb(204, 230, 255)\",\"rgb(0, 136, 204)\",\"rgb(0, 255, 191)\",\"rgb(204, 255, 153)\",\"rgb(255, 255, 102)\",\"rgb(255, 204, 153)\",\"rgb(255, 102, 0)\",\"rgb(204, 0, 102)\",\"rgb(102, 0, 102)\"],\n",
    "    symbol_advanced_table_height_list    = 0.5\n",
    ")\n",
    "\n",
    "# Plot\n",
    "mv.plot(my_coast,my_symbol,g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
